<!DOCTYPE html>
<html>
<head>
<title>2024-2025小学期大数据系统开发实践报告.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<div style="display:grid; justify-content:center;">
<br/>
<br/>
<br/>
<br/>
<p><img src="image.png" alt="alt text"></p>
<h1 id="%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A">大数据系统开发实践实验报告</h1>
<br>
<br>
<br>
<div style = "display:grid; justify-content: center; align-items: flex-start;">
<h3 id="%E9%A2%98-%E7%9B%AE-u%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5-u">题　　目： <u>大数据系统开发实践         </u></h3>
<h3 id="%E5%AD%A6-%E9%99%A2-u%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2-u">学　　院： <u>计算机学院             </u></h3>
<h3 id="%E4%B8%93%E4%B8%9A%E5%90%8D%E7%A7%B0-u%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF-u">专业名称： <u>计算机科学与技术          </u></h3>
<h3 id="%E5%B0%8F%E7%BB%84%E6%88%90%E5%91%98-u%E7%AA%A6%E7%BF%8A%E6%81%92-%E7%8E%8B%E5%87%AF%E9%9B%AF-%E5%8F%B6%E5%AE%B6%E5%B8%8C-%E5%BC%A0%E9%9D%96%E4%BB%81u">小组成员： <u>窦翊恒， 王凯雯， 叶家希， 张靖仁</u></h3>
<h3 id="%E4%BB%BB%E8%AF%BE%E6%95%99%E5%B8%88-u%E9%83%AD%E8%B4%B5%E9%94%81-u">任课教师： <u>郭贵锁               </u></h3>
<h3 id="%E6%97%A5-%E6%9C%9F-u2024%E5%B9%B49%E6%9C%8814%E6%97%A5-u">日　　期： <u>2024年9月14日         </u></h3>
</div>
<br>
<br>
</div>
<div style="page-break-after: always;"></div>
<h2 id="1%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E6%8A%80%E6%9C%AF%E6%96%B9%E6%A1%88">1.搜索引擎的技术方案</h2>
<h3 id="11%E5%8A%9F%E8%83%BD%E6%8F%8F%E8%BF%B0">1.1功能描述</h3>
<p>  本搜索引擎系统的主要功能模块包括：</p>
<ol>
<li>
<p><strong>数据采集模块</strong></p>
<ul>
<li>负责从互联网上抓取网页内容，并将其存储到分布式存储中。</li>
</ul>
</li>
<li>
<p><strong>数据预处理模块</strong></p>
<ul>
<li>对采集到的数据进行清洗和规范化，包括去除HTML标签、标点符号处理、分词等。</li>
</ul>
</li>
<li>
<p><strong>索引构建模块</strong></p>
<ul>
<li>实现倒排索引结构，支持高效的查询和检索功能。</li>
<li>利用MapReduce算法进行索引的构建和更新。</li>
</ul>
</li>
<li>
<p><strong>查询处理模块</strong></p>
<ul>
<li>负责接收用户查询请求，解析查询内容，并利用倒排索引快速查找匹配文档。</li>
</ul>
</li>
<li>
<p><strong>结果排序模块</strong></p>
<ul>
<li>根据一定的算法（如TF-IDF、BM25）对检索到的结果进行排序，提升用户体验。</li>
</ul>
</li>
<li>
<p><strong>用户接口模块</strong></p>
<ul>
<li>提供用户友好的搜索界面，展示查询结果并支持多种过滤选项。</li>
</ul>
</li>
<li>
<p><strong>监控与日志模块</strong></p>
<ul>
<li>记录系统运行状态、用户行为以及错误日志，便于系统维护和性能优化。</li>
</ul>
</li>
</ol>
<h3 id="12%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B">1.2技术选型</h3>
<p>  随着搜索引擎需要处理超高并发和超大数据量，国内多数搜索引擎采用集中式架构，导致服务器性能要求高、可扩展性差、宽带浪费和重复性工作等问题，难以应对日益增长的数据规模。而基于分布式架构的搜索引擎，如Hadoop，能够提供高性能、低成本的解决方案，因此在搜索引擎中引入Hadoop是必要的。<br></p>
<h4 id="hadoop-%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B">Hadoop 生态系统简介</h4>
<p>  Hadoop是Apache基金会开发的开源分布式系统基础架构，具有高扩展性和容错性。它的核心组件包括：<br></p>
<ul>
<li><strong>HDFS（Hadoop Distributed File System）</strong>：分布式存储系统，采用Master/Slave结构，负责将文件拆分成多个数据块存储在不同节点上。<br></li>
<li><strong>YARN（Yet Another Resource Negotiator）</strong>：集群资源管理和任务调度的核心框架。<br></li>
<li><strong>MapReduce</strong>：Hadoop的数据处理引擎，支持大数据的并行计算。<br></li>
<li><strong>HBase</strong>：面向列的分布式数据库，适用于大规模数据的随机读写。<br></li>
<li><strong>Hive</strong>：基于Hadoop的数据仓库工具，支持SQL查询。<br></li>
<li><strong>Spark</strong>：通用的大数据快速计算引擎，适合低延迟和迭代处理需求。<br></li>
<li><strong>ZooKeeper</strong>：分布式协调服务，负责系统的配置管理、同步和故障恢复。<br>
Hadoop的核心是HDFS提供存储支持，MapReduce负责数据计算。基于这些特点，Hadoop可以很好地满足分布式搜索引擎的需求。<br></li>
</ul>
<h4 id="121-hadoop-%E7%9A%84%E4%BC%98%E5%8A%BF">1.2.1 Hadoop 的优势</h4>
<ol>
<li><strong>高效的数据处理</strong>：通过MapReduce并行处理大量数据，能显著减少数据处理时间。例如，18GB数据在集群环境下比单机节省了4.8倍的时间。随着数据规模的增加，Hadoop的效率优势愈发明显。<br></li>
<li><strong>开源与低成本</strong>：Hadoop是开源平台，使用成本较低，团队可以将更多资金投入到应用开发中。开源带来了快速的技术更新和社区支持。<br></li>
<li><strong>高扩展性</strong>：Hadoop支持集群扩展，能动态添加计算节点，以满足不断增加的数据处理需求，且不会影响集群的性能。<br></li>
<li><strong>安全性和容错性</strong>：HDFS通过数据块的副本机制确保数据安全，系统可以从节点故障中快速恢复。Hadoop自动分配失败任务，确保任务的连续性和数据的完整性。<br></li>
<li><strong>适合中小型团队</strong>：Hadoop的架构能够减少对硬件的依赖，使中小型开发团队可以在有限的资源下实现高效的数据分析和搜索服务。<br></li>
</ol>
<h4 id="122-hadoop-%E7%9A%84%E5%8A%A3%E5%8A%BF">1.2.2 Hadoop 的劣势</h4>
<p>  尽管Hadoop有许多优势，但在某些场景中仍然存在一些局限性，特别是在Hadoop 3.x版本中体现得更为明显：<br></p>
<ol>
<li><strong>不适用于低延迟的数据访问</strong>：Hadoop主要适合批处理任务，不适合需要快速响应的实时应用场景。<br></li>
<li><strong>处理大量小文件效率低</strong>：Hadoop的文件块默认大小为128MB或256MB，处理大量比块大小小得多的文件时（如小于1MB），效率较低。这些小文件会使NameNode超载，导致性能瓶颈。<br></li>
<li><strong>不支持多用户同时写入和修改文件</strong>：HDFS对文件的修改限制较多，无法灵活地进行多用户并发写入和修改操作。<br></li>
<li><strong>安全性问题</strong>：由于Hadoop使用Java编写，而Java作为一种广泛使用的语言，容易成为网络攻击的目标，Hadoop系统的安全性容易受到挑战。<br></li>
<li><strong>处理开销大</strong>：Hadoop依赖磁盘I/O，数据从磁盘读取和写入的过程耗时较长，特别是在处理PB级数据时，读写操作变得非常昂贵。Hadoop无法实现内存中计算，导致整体处理开销大。<br></li>
<li><strong>仅支持批处理</strong>：Hadoop的核心MapReduce引擎设计用于批处理任务，不适合流处理或需要低延迟的实时应用。<br></li>
<li><strong>迭代处理效率低</strong>：Hadoop的MapReduce模型不适合迭代处理，特别是在机器学习或需要多阶段处理的数据流中。每个阶段的输出必须作为下一个阶段的输入，缺乏灵活性。<br></li>
</ol>
<h4 id="123-%E7%BB%93%E8%AE%BA">1.2.3 结论</h4>
<p>  Hadoop凭借其高效、低成本、易扩展的特点，适合作为分布式搜索引擎的基础架构。然而，对于实时性要求高或涉及大量小文件的场景，Hadoop的效率会大打折扣。在这种情况下，可以考虑将Hadoop与其他大数据工具（如Spark）结合使用，以弥补其不足，提高搜索引擎的性能和灵活性。<br></p>
<h3 id="13-%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0">1.3 功能实现</h3>
<h4 id="131-%E5%88%9D%E5%A7%8B%E6%96%87%E4%BB%B6%E5%88%87%E5%88%86%E4%B8%8E%E5%AD%98%E5%82%A8">1.3.1 初始文件切分与存储</h4>
<p>  将老师发布的sentences.txt.zip解压，利用python程序把文档拆分成940个小文件，分别命名为file0-file939。<br>
将拆分后的文件上传到HDFS，实现分布式存储。<br></p>
<h4 id="132-mapreduce%E5%88%9B%E5%BB%BA%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95">1.3.2 MapReduce创建倒排索引</h4>
<p>  使用 MapReduce 对存储在 HDFS 中的文件进行倒排索引的计算，这样可以根据查询的关键词返回包含该关键词的文档列表。<br></p>
<ul>
<li><strong>Map 阶段</strong>：对每个文件进行逐词解析，将每个词和它所在的文件路径作为键值对输出。<br></li>
<li><strong>Reduce 阶段</strong>：将相同的词汇合并，输出该词出现在的所有文件路径。<br></li>
</ul>
<h4 id="133-%E5%B0%86%E7%B4%A2%E5%BC%95%E5%AD%98%E5%82%A8%E5%88%B0hbase">1.3.3 将索引存储到HBase</h4>
<p>  在Hbase中创建一个表InvertedIndexTable，它的行键是每个词，列族存储该词对应的文件路径列表。<br></p>
<h4 id="134-%E5%AE%9E%E7%8E%B0%E6%9F%A5%E8%AF%A2%E5%8A%9F%E8%83%BD">1.3.4 实现查询功能</h4>
<p>  在HBase中输入需要查询的词，利用倒排索引快速呈现查询结果。<br></p>
<h4 id="135-%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90">1.3.5 实例分析</h4>
<p>  从老师发布的文件获取原始数据，解压后通过python程序将大文件分割成940个小文件，然后将文件内容上传到hdfs。然后利用MapReduce代码对文件分别进行处理。代码的具体逻辑是在Map阶段生成单词和文档ID的键值对并传输给Combine模块，Combine阶段对Map的键值对进行基础的归并和排序，Reduce阶段对单词在每个文件中出现的次数进行相加并写入HBase中。<br>
  当用户在HBase中输入搜索内容后，HBase会自动列出该单词和所有存储了该单词的文件。</p>
<h3 id="14-%E5%B7%A5%E4%BD%9C%E8%AE%A1%E5%88%92">1.4 工作计划</h3>
<p><strong>阶段一：设计Hadoop分布式计算引擎</strong><br>
<strong>目标</strong>：建立一个基于Hadoop的分布式计算引擎，支持海量数据的高效处理。<br></p>
<p><strong>任务</strong>：<br>
  研究Hadoop框架的基本原理和组件（如HDFS、MapReduce、YARN等）。<br>
  设计适用于搜索引擎的数据处理架构，特别是数据抓取和预处理的管道。<br>
  实现Hadoop集群的部署与配置，确保高可用性和扩展性。<br>
  优化Hadoop作业的执行，减少数据处理的延迟和资源消耗。<br>
  重点：选择合适的调度算法和数据分区策略，以优化数据抓取和处理的性能。<br></p>
<p><strong>阶段二：嵌入倒排索引技术（全文检索）</strong><br>
<strong>目标</strong>：实现基于倒排索引的全文检索功能，以支持高效的搜索查询。<br></p>
<p><strong>任务</strong>：<br>
  理解倒排索引的结构和构建过程，包括词项、文档频率、倒排列表等。<br>
  设计倒排索引的生成算法，确保索引构建的效率和准确性。<br>
  集成全文检索库（如Lucene），或者自定义开发全文检索模块。<br>
  实现索引更新策略（增量更新、全量重建等）以适应动态数据变化。<br>
  重点：优化索引存储结构和查询算法，提升查询的响应速度和准确性。<br></p>
<p><strong>阶段三：实现中文分词技术</strong><br>
<strong>目标</strong>：设计并实现中文分词算法，提高中文搜索结果的准确性。<br></p>
<p><strong>任务</strong>：<br>
  调研现有的中文分词算法（如正向最大匹配、双向最大匹配、统计模型等）并选型。<br>
  实现分词算法并进行性能优化，支持自定义词典和词性标注。<br>
  解决分词中的歧义问题，提高分词的准确率。<br>
  集成分词模块与倒排索引构建过程，以支持中文文本的有效索引和检索。<br>
  重点：平衡分词的准确性和性能，处理好词库维护和动态更新的问题。<br></p>
<p><strong>阶段四：设计分布式数据库系统</strong><br>
<strong>目标</strong>：设计一个高效的分布式数据库系统，用于存储和管理海量数据。<br></p>
<p><strong>任务</strong>：<br>
  分析业务需求，确定需要存储的数据类型（文档元数据、用户行为数据等）。<br>
  选型分布式数据库系统（如HBase、Cassandra、Elasticsearch等），并设计数据模型。<br>
  设计数据库的分区和副本策略，以提高数据的读写性能和可靠性。<br>
  优化数据库的索引策略，确保高效的数据查询和检索性能。<br>
  重点：设计合理的数据分片和副本管理策略，平衡数据一致性和可用性。<br>
<br>
<strong>阶段五：开发Web客户端</strong><br>
<strong>目标</strong>：开发一个友好的Web前端，提供用户高效的搜索体验。<br>
<br>
<strong>任务</strong>：<br>
  设计用户界面（UI）和用户体验（UX），确保简洁易用的操作流程。<br>
  实现前端功能模块（如搜索框、搜索结果展示、过滤器等）。<br>
  提供智能提示和自动补全功能，以提高用户输入效率。<br>
  集成前端与后端API接口，确保数据的实时性和准确性。<br>
  重点：关注用户体验，确保前端页面的响应速度和交互性。<br>
<br>
<strong>阶段六：测试和功能完善</strong><br>
<strong>目标</strong>：全面测试系统功能，修复缺陷并优化性能。<br>
<br>
<strong>任务</strong>：<br>
  制定测试计划，进行单元测试、集成测试、性能测试和用户测试。<br>
  收集测试反馈，修复Bug和优化功能，确保系统的稳定性和可用性。<br>
  完善日志和监控系统，确保故障的快速定位和恢复。<br>
  进行负载测试和安全测试，优化系统的扩展性和安全性。<br>
  重点：全面测试和持续优化，确保系统在高并发和大数据量下的稳定运行。<br></p>
<h3 id="15-%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84">1.5 组织结构</h3>
<h4 id="151-%E5%88%86%E5%B7%A5%E6%9E%B6%E6%9E%84">1.5.1 分工架构</h4>
<p>1.<strong>项目经理（1人）</strong><br>
  项目经理负责整体项目规划和协调，确保项目按时交付。担当决策关键技术选型的责任，协调各团队成员的工作，并与相关利益方保持沟通。<br>
2.<strong>系统架构师（2人）</strong><br>
  系统架构师负责设计整体系统架构，确保系统的可扩展性和高性能。制定核心技术实现方案，为开发团队提供技术支持和指导。<br>
3.<strong>开发工程师（3人）</strong><br>
  开发团队负责具体的技术实现，包括文件分割、索引构建、查询处理、结果排序等任务。通过协同工作，确保后端系统的高效运行和数据处理。<br>
4.<strong>测试工程师（2人）</strong><br>
  测试团队负责进行系统测试和性能测试，确保系统的稳定性和可靠性。通过全面的测试，提供反馈和建议，帮助优化系统的性能和功能。<br></p>
<h4 id="152-%E4%BA%BA%E5%91%98%E5%88%86%E9%85%8D">1.5.2 人员分配</h4>
<table>
<thead>
<tr>
<th>学号</th>
<th>姓名</th>
<th>角色分工</th>
</tr>
</thead>
<tbody>
<tr>
<td>1120223574</td>
<td>张靖仁</td>
<td>系统架构师、开发工程师</td>
</tr>
<tr>
<td>1120222100</td>
<td>窦翊恒</td>
<td>系统架构师、测试工程师</td>
</tr>
<tr>
<td>1120221327</td>
<td>王凯雯</td>
<td>项目经理、开发工程师</td>
</tr>
<tr>
<td>1120221310</td>
<td>叶家希</td>
<td>开发工程师、测试工程师</td>
</tr>
</tbody>
</table>
<h3 id="16-%E8%BD%AF%E4%BB%B6%E8%B4%A8%E9%87%8F%E4%BF%9D%E8%AF%81">1.6 软件质量保证</h3>
<h4 id="%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95">功能测试</h4>
<ul>
<li>
<p><strong>索引功能</strong>：</p>
<ol>
<li>准备测试文档集。</li>
<li>运行索引过程。</li>
<li>查询已索引的文档，验证是否能正确返回。</li>
</ol>
</li>
<li>
<p><strong>查询功能</strong>：</p>
<ol>
<li>设计多种查询场景（包含关键词、短语、布尔查询等）。</li>
<li>执行查询并记录结果。</li>
<li>验证返回结果的准确性和完整性。</li>
</ol>
</li>
<li>
<p><strong>验证测试结果</strong>：</p>
<ol>
<li>确认搜索结果的格式和内容。</li>
<li>检查分页功能和排序选项。</li>
<li>验证链接和资源的有效性。</li>
</ol>
</li>
</ul>
<h4 id="%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95">性能测试</h4>
<ul>
<li>
<p><strong>负载测试</strong>：</p>
<ol>
<li>使用 JMeter 设置模拟用户场景。</li>
<li>逐步增加用户数量，记录系统性能指标。</li>
<li>分析系统的稳定性和瓶颈。</li>
</ol>
</li>
<li>
<p><strong>响应时间</strong>：</p>
<ol>
<li>记录每次查询的响应时间。</li>
<li>计算平均响应时间，并与预设标准比较。</li>
<li>针对超时请求进行详细分析。</li>
</ol>
</li>
<li>
<p><strong>数据处理速度</strong>：</p>
<ol>
<li>测量索引过程的时间。</li>
<li>评估新数据添加或更新的速度。</li>
<li>检查数据在集群中的同步时间。</li>
</ol>
</li>
</ul>
<h4 id="%E5%AE%89%E5%85%A8%E6%80%A7%E6%B5%8B%E8%AF%95">安全性测试</h4>
<ul>
<li>
<p><strong>身份验证</strong>：</p>
<ol>
<li>尝试使用有效和无效的用户凭据进行登录。</li>
<li>验证成功和失败的登录提示。</li>
</ol>
</li>
<li>
<p><strong>数据隐私</strong>：</p>
<ol>
<li>使用抓包工具监控数据传输过程。</li>
<li>确认敏感数据是否加密。</li>
</ol>
</li>
<li>
<p><strong>权限控制</strong>：</p>
<ol>
<li>创建不同权限的用户账户。</li>
<li>验证用户只能访问其权限范围内的数据。</li>
</ol>
</li>
</ul>
<h4 id="%E5%85%BC%E5%AE%B9%E6%80%A7%E6%B5%8B%E8%AF%95">兼容性测试</h4>
<ul>
<li>
<p><strong>跨平台测试</strong>：</p>
<ol>
<li>在不同操作系统（Windows、Linux、macOS）上运行搜索引擎。</li>
<li>在主要浏览器（Chrome、Firefox、Safari）中测试界面和功能。</li>
</ol>
</li>
<li>
<p><strong>版本兼容性</strong>：</p>
<ol>
<li>检查与不同版本的 Hadoop 和相关库的兼容性。</li>
<li>记录任何出现的兼容性问题。</li>
</ol>
</li>
</ul>
<h4 id="%E5%9B%9E%E5%BD%92%E6%B5%8B%E8%AF%95">回归测试</h4>
<ul>
<li><strong>测试更新后功能</strong>：
<ol>
<li>记录最新更改和修复的功能。</li>
<li>针对所有功能重新执行测试，确保未引入新问题。</li>
</ol>
</li>
</ul>
<h4 id="%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95">自动化测试</h4>
<ul>
<li><strong>编写测试脚本</strong>：
<ol>
<li>使用 Selenium 或 JUnit 编写自动化测试脚本。</li>
<li>定期运行测试，确保功能稳定。</li>
</ol>
</li>
</ul>
<h3 id="17-%E8%BD%AF%E4%BB%B6%E9%9D%9E%E5%8A%9F%E8%83%BD%E6%80%A7%E4%BF%9D%E8%AF%81">1.7 软件非功能性保证</h3>
<ol>
<li>
<p><strong>性能保证</strong>：</p>
<ul>
<li><strong>响应时间</strong>：确保搜索引擎在特定条件下的响应速度符合要求。</li>
<li><strong>吞吐量</strong>：处理请求的能力，确保在高负载下系统仍能正常运行。</li>
</ul>
</li>
<li>
<p><strong>可靠性保证</strong>：</p>
<ul>
<li><strong>可用性</strong>：搜索引擎的在线时间和稳定性，通常要求高可用性。</li>
<li><strong>故障恢复</strong>：在发生故障时能够迅速恢复至正常状态。</li>
</ul>
</li>
<li>
<p><strong>安全性保证</strong>：</p>
<ul>
<li><strong>数据保护</strong>：确保敏感数据的加密和安全存储。</li>
<li><strong>访问控制</strong>：通过身份验证和授权管理用户权限。</li>
</ul>
</li>
<li>
<p><strong>可维护性保证</strong>：</p>
<ul>
<li><strong>代码可读性</strong>：确保代码结构清晰，便于后续维护和更新。</li>
<li><strong>文档齐全</strong>：提供详细的技术文档和用户指南。</li>
</ul>
</li>
<li>
<p><strong>兼容性保证</strong>：</p>
<ul>
<li><strong>平台兼容性</strong>：确保软件在不同操作系统和硬件上的兼容性。</li>
<li><strong>版本兼容性</strong>：支持与其他软件和库的兼容性。</li>
</ul>
</li>
<li>
<p><strong>可用性保证</strong>：</p>
<ul>
<li><strong>用户友好性</strong>：Web界面设计应直观，提升用户体验。</li>
<li><strong>错误处理</strong>：提供清晰的错误信息，帮助用户理解问题。</li>
</ul>
</li>
</ol>
<h3 id="18-%E8%BD%AF%E4%BB%B6%E7%BB%B4%E6%8A%A4">1.8 软件维护</h3>
<h4 id="%E6%97%A5%E5%BF%97%E5%92%8C%E7%9B%91%E6%8E%A7">日志和监控</h4>
<ul>
<li>
<p><strong>设置日志记录</strong>：</p>
<ol>
<li>配置日志系统，记录关键操作和错误信息。</li>
<li>定期审查日志，发现潜在问题。</li>
</ol>
</li>
<li>
<p><strong>监控系统性能</strong>：</p>
<ol>
<li>使用监控工具（如 Grafana）跟踪系统性能指标。</li>
<li>设定警报，及时处理异常情况。</li>
</ol>
</li>
</ul>
<br>
<h2 id="2%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%9A%84%E5%AE%9E%E7%8E%B0">2.倒排索引的实现</h2>
<h3 id="21-%E5%AE%9E%E9%AA%8C%E8%A6%81%E6%B1%82">2.1 实验要求</h3>
<p>  运用MapReduce算法计算,构建一个倒排索引, 将倒排索引存储在HBase中,数据为老师提供的sentence.txt文件。</p>
<h3 id="22-%E5%AE%9E%E9%AA%8C%E8%BF%9B%E5%BA%A6">2.2 实验进度</h3>
<ul>
<li>9.6-9.8 完成集群初步配置<br></li>
<li>9.9-9.11 伪分布式和单机完全分布式集群启动成功<br></li>
<li>9.12 完成倒排索引的代码编写<br></li>
<li>9.13 完成三机完全分布式集群启动成功，单机完全分布式倒排运行成功<br></li>
<li>9.14 三机完全分布式倒排运行成功</li>
</ul>
<h3 id="23-%E5%B0%8F%E7%BB%84%E5%88%86%E5%B7%A5">2.3 小组分工</h3>
<table>
<thead>
<tr>
<th>学号</th>
<th>姓名</th>
<th>实验负责内容</th>
<th>文档负责内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>1120223574</td>
<td>张靖仁</td>
<td>1. 初步配置单机完全分布hadoop环境<br>2. 完成MapReduce的代码实现<br>3. 参与三台设备完全分布环境的调试，实现倒排索引在完全分布环境上运行<br></td>
<td>1. 搜索引擎技术文档负责撰写软件质量保证、非功能性保证、软件维护部分 <br>2. 实验报告负责撰写算法及实现部分</td>
</tr>
<tr>
<td>1120222100</td>
<td>窦翊恒</td>
<td>1. 负责网络的架构，调试完全分布的网络配置以实现不同主机之间的通信与文件传输<br>2. 配置修改完全分布的Hadoop环境<br>3. 完成数据处理与准备部分代码实现<br>4.  参与三台设备完全分布环境的调试，实现倒排索引在完全分布环境上运行</td>
<td>1. 搜索引擎技术文档负责撰写技术选型、工作计划部分<br>2. 实验报告负责撰写数据准备、实验进度要求、完全分布集群网络配置部分</td>
</tr>
<tr>
<td>1120221327</td>
<td>王凯雯</td>
<td>1. 负责配置单机完全分布hadoop环境<br>2.调试三机完全分布的环境，实现倒排索引在完全分布环境上运行<br>3.负责单机完全分布的倒排索引程序的运行调试，并导入数据库<br>4.编写了文件导入hdfs的代码</td>
<td>1. 搜索引擎技术文档负责撰写功能描述部分<br>2. 实验报告负责撰写环境的安装与配置的分布式环境配置、实验结果分析部分</td>
</tr>
<tr>
<td>1120221310</td>
<td>叶家希</td>
<td>1.负责配置单机伪分布hadoop环境<br>2.调试单机伪分布的环境，实现倒排索引在伪分布环境上运行<br>3.负责单机伪分布的倒排索引程序的运行调试，并导入数据库<br>4.通过命令行将单机本地文件上传到hdfs<br></td>
<td>1. 搜索引擎技术文档负责撰写功能实现部分<br>2. 实验报告负责撰写环境的安装与配置的伪分布环境配置、实验运行结果与分析部分</td>
</tr>
</tbody>
</table>
<h3 id="24-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87">2.4 数据准备</h3>
<p>  数据来自i北理群，解压sentence压缩包后其中sentence.txt为1.392316kb。通过由于文件过大无法使用记事本打开，通过python代码显示文本内容，得到一共有9397023行，每行有一个行号（0-9397022）和一个英文长句，相邻单词用空格分离。数据中仅包含数字与英文字母，无特殊符号。<br>
<strong>数据处理</strong><br>
  运行wordcut.py将同目录下的sentence.txt按照每一万行句子进行划分，并将划分好的940个文件命名为files0~files939，并存入files文件夹中。<br>
wordcut.py代码如下<br></p>
<pre class="hljs"><code><div>import os
import math
# 指定输入文件和输出目录
input_file_path = r&quot;sentences.txt&quot;  # 输入的txt文件路径
output_directory = r'files'  # 指定的输出目录路径
# 打开原始txt文件,一共有9397023条句子
with open(input_file_path, 'r', encoding='utf-8') as input_file:
    lines = input_file.readlines()
# 计算总行数和文件数
total_lines = len(lines)
num_files = (total_lines + 9999) // 10000
# 分割文件
for i in range(num_files):
    start = i * 10000
    end = min((i + 1) * 10000, total_lines)
    output_filename = os.path.join(output_directory, f'file{i}.txt')

    # 写入分割后的内容到新文件
    with open(output_filename, 'w', encoding='utf-8') as output_file:
        output_file.writelines(lines[start:end])
</div></code></pre>
<h3 id="25-%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE">2.5 环境的安装与配置</h3>
<h4 id="251-%E4%BC%AA%E5%88%86%E5%B8%83">2.5.1 伪分布</h4>
<ol>
<li>
<p>节点分配设计</p>
<p>  因为是单机伪分布，所有类型的节点都布局在一台机器上，包括NameNode，SecondaryNameNode，DataNode，ResourceManager，NodeManager和Zookeeper，每个节点的具体分工见完全分布的表格。
<br></p>
</li>
<li>
<p>使用SSH连接</p>
<p>  单机伪分布需要在一台机器上协调各个节点的进程，因此也需要SSH免密连接首先使用如下命令创建RSA密钥对，RSA密钥对应该在客户端申请，在此处就是在CentOS7中申请。</p>
<pre class="hljs"><code><div>ssh-keygen
</div></code></pre>
<p>  然后直接使用如下命令将id_rsa.pub复制到服务端，因为是单机伪分布，服务端还是本台机器，直接将远程地址改为localhost.</p>
<pre class="hljs"><code><div>ssh-copy-id localhost
</div></code></pre>
<p>  然后检查~/.ssh目录下的authorized_keys文件，发现id_rsa.pub的内容已被复制，说明SSH免密连接成功（注意.ssh目录是一个隐藏目录，在~目录下直接使用ls命令不会显示，但是可以通过cd进入）。
<br>
  为了后续操作方便起见，再在Windows中创建一组密钥对然后将密钥复制到CentOS，使得可以通过XShell访问虚拟机以及能通过Windows的Web端UI检查集群等。
<br></p>
</li>
<li>
<p>软件安装与节点配置文件</p>
<p>  软件的下载与安装过程与完全分布并无太大差异，下文完全分布会展开，此处不再赘述，但由于单机与三机的内存差异，在配置文件中可能会略有不同，因此以下详细罗列各个软件的配置文件。</p>
</li>
</ol>
<ul>
<li>
<p><strong>core-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;fs.defaultFS&lt;/name&gt;
  &lt;value&gt;hdfs://hadoop:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/opt/module/hadoopTmp/&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>hdfs-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
  &lt;property&gt;
  &lt;!-- 设置HDFS元数据文件存放路径 --&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;/opt/module/hd_space/hdfs/name&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
  &lt;!-- 设置HDFS数据文件存放路径 --&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;/opt/module/hd_space/hdfs/data&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
  &lt;!-- 设置HDFS数据文件副本数 --&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
  &lt;!-- 设置其他用户执行操作时会提醒没有权限 --&gt;
    &lt;name&gt;dfs.permissions&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>yarn-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
  &lt;property&gt;
  	&lt;name&gt;yarn.resourcemanager.hostsname&lt;/name&gt;
  	&lt;value&gt;hadoop&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
  	&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
  	&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
  	&lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
  	&lt;value&gt;3072&lt;/value&gt; &lt;!-- 最大任务内存设置为2GB --&gt;
  &lt;/property&gt;
  &lt;property&gt;
  	&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
  	&lt;value&gt;3072&lt;/value&gt; &lt;!-- YARN NodeManager总内存设置为3GB内存中的2.5GB左右，留出一些空间给系统和其他进程 --&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>mapred-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
  &lt;property&gt;
   	&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
   	&lt;value&gt;yarn&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
	  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
	  &lt;value&gt;HADOOP_MAPRED_HOME=/opt/module/hadoop-3.3.5&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
	  &lt;name&gt;mapreduce.map.env&lt;/name&gt;
      &lt;value&gt;HADOOP_MAPRED_HOME=/opt/module/hadoop-3.3.5&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
      &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
      &lt;value&gt;HADOOP_MAPRED_HOME=/opt/module/hadoop-3.3.5&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>hbase-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
  &lt;property&gt;
 	  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
 	  &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
 	  &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
 	  &lt;value&gt;./tmp&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
 	  &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;
 	  &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
      &lt;name&gt;hbase.rootdir&lt;/name&gt;
      &lt;value&gt;hdfs://hadoop:9000/hbase&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.master&lt;/name&gt;
      &lt;value&gt;hadoop:60000&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
      &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
      &lt;value&gt;hadoop&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;2181&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
      &lt;name&gt;hbase.master.port&lt;/name&gt;
      &lt;value&gt;16000&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
      &lt;name&gt;hbase.master.info.port&lt;/name&gt;
      &lt;value&gt;16010&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
      &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;
      &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
      &lt;name&gt;hbase.wal.provider&lt;/name&gt;
      &lt;value&gt;filesystem&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
</ul>
<ol start="4">
<li>
<p>单机伪分布集群启动</p>
<p>  在虚拟机初始状态下输入jps查看当前运行进程，很明显只有jps一条，集群未启动
<br>
<img src="init.png" alt="alt text">
<br>
  进入hadoop安装解压后的sbin目录，利用start-all.sh开启hadoop集群
<br>
  再使用jps命令，发现此时的进程除了jps多了几条
<br>
<img src="hd.png" alt="alt text">
<br>
  然后进入网页端UI检查集群是否启动成功
网页端口名分别为http://hadoop:9870和http://hadoop:8088
界面显示如下，说明hadoop集群启动成功<br>
<img src="9870.png" alt="alt text">
<br>
<img src="8088.png" alt="alt text">
<br>
  接着进入zookeeper安装解压后的bin目录，利用zkServer.sh start启用zookeeper，同样通过jps检查，发现当前新增了一个进程QuorumPeerMain，说明zookeeper启动成功
<br>
<img src="zk.png" alt="alt text">
<br>
  最后进入hbase安装解压后的bin目录，利用start-hbase.sh启动hbase，检查jps发现多了HMaster和HRegionServer两项进程
<br>
<img src="hbase.png" alt="alt text">
<br>
  最后再进入hbase的WebUI检查启动是否成功 网络端口号为http://hadoop:16010
<br>
<img src="16010.png" alt="alt text">
<br>
  该图片显示启动成功。
<br></p>
</li>
</ol>
<h4 id="252%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83">2.5.2完全分布</h4>
<ol>
<li>节点分配设计</li>
</ol>
<table>
<thead>
<tr>
<th>节点编号</th>
<th>节点类型</th>
<th>IP地址</th>
<th>角色/职责</th>
<th>CPU核数</th>
<th>内存(GB)</th>
<th>磁盘空间(GB)</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>NameNode</td>
<td>192.168.3.81</td>
<td>管理HDFS元数据，负责文件系统的命名空间和控制</td>
<td>2</td>
<td>2</td>
<td>40</td>
<td>主要负责元数据存储与查询</td>
</tr>
<tr>
<td>2</td>
<td>SecondaryNameNode</td>
<td>192.168.3.83</td>
<td>协助NameNode备份元数据、检查点</td>
<td>8</td>
<td>2</td>
<td>40</td>
<td>作为NameNode的辅助节点</td>
</tr>
<tr>
<td>3</td>
<td>DataNode</td>
<td>192.168.3.81</td>
<td>存储实际数据块，提供数据读写服务</td>
<td>2</td>
<td>2</td>
<td>40</td>
<td>每个DataNode存储HDFS数据块</td>
</tr>
<tr>
<td>4</td>
<td>DataNode</td>
<td>192.168.3.82</td>
<td>存储实际数据块，提供数据读写服务</td>
<td>2</td>
<td>2</td>
<td>40</td>
<td>多个DataNode提供冗余和高可用性</td>
</tr>
<tr>
<td>5</td>
<td>DataNode</td>
<td>192.168.3.83</td>
<td>存储实际数据块，提供数据读写服务</td>
<td>8</td>
<td>2</td>
<td>40</td>
<td>提供负载均衡和分布式存储</td>
</tr>
<tr>
<td>6</td>
<td>ResourceManager</td>
<td>192.168.3.81</td>
<td>管理集群资源，调度计算任务</td>
<td>2</td>
<td>2</td>
<td>40</td>
<td>负责资源调度</td>
</tr>
<tr>
<td>7</td>
<td>NodeManager</td>
<td>192.168.3.82</td>
<td>负责任务执行及资源管理</td>
<td>2</td>
<td>2</td>
<td>40</td>
<td>管理YARN应用程序的容器</td>
</tr>
<tr>
<td>8</td>
<td>NodeManager</td>
<td>192.168.3.83</td>
<td>负责任务执行及资源管理</td>
<td>8</td>
<td>2</td>
<td>40</td>
<td>提供计算能力的分布式资源节点</td>
</tr>
<tr>
<td>9</td>
<td>Zookeeper</td>
<td>192.168.3.83</td>
<td>提供分布式协调服务，管理集群节点状态</td>
<td>8</td>
<td>2</td>
<td>40</td>
<td>负责NameNode的高可用性和选举</td>
</tr>
</tbody>
</table>
<ol start="2">
<li>网络配置流程</li>
</ol>
<ul>
<li>
<p><strong>设置IP地址</strong><br>
  需要修改主机VM8，虚拟网络编辑器和虚拟机网卡。<br>
  首先是VMnet8的设置：<br>
<img src="image-1.png" alt="alt text"><br>
  将IP，网关和DNS的第三位调整一致。<br>
   然后设置虚拟网络编辑器：<br>
<img src="image-2.png" alt="alt text"><br>
  将子网的网段前三位改为与VMnet8的IP一致。<br>
  然后配置虚拟机网卡，在命令终端输入<br></p>
<pre class="hljs"><code><div>$ vim /etc/sysconfig/network-scripts/ifcfg-ens33
</div></code></pre>
<p>  进入页面修改虚拟机的网卡如下图所示：<br>
<img src="image-3.png" alt="alt text"><br>
  至此，所有IP配置完毕</p>
</li>
<li>
<p><strong>使用XShell连接</strong><br>
  如果可以使用XShell连接，说明本地的网络与虚拟机服务器之间的网络是畅通的，没有防火墙或其他网络障碍阻止连接。所以这步需要先关闭防火墙，确认访问端口开启，然后再用XShell连接，连接成功后ping外网和本机IP，保证网络畅通。<br>
  首先关闭防火墙，并检查防火墙状态:</p>
<pre class="hljs"><code><div>$ sudo systemctl stop firewalld
$ sudo systemctl disable firewalld
$ sudo systemctl status firewalld
</div></code></pre>
<p>  出现以下状态即为关闭成功：<img src="image-4.png" alt="alt text"><br>
  然后检查开放的端口：</p>
<pre class="hljs"><code><div>$ sudo ss -tuln
</div></code></pre>
<p>  检查端口是否开放<br>
<img src="image-5.png" alt="alt text">
  可以看到22号端口是开放的。<br>
  然后我们使用XShell对其进行连接：<br>
<img src="image-6.png" alt="alt text">图示即为连接成功。<br>
  然后测试ping网络：<br>
<img src="image-7.png" alt="alt text"><br>
  如图即为成功ping通。至此已经完成XShell的连接.<br></p>
</li>
</ul>
<ol start="3">
<li>软件安装和虚拟机复制</li>
</ol>
<ul>
<li>
<p><strong>jdk安装</strong></p>
<p>  将jdk压缩包解压至指定目录下，打开etc/profile进行环境变量的修改：</p>
<pre class="hljs"><code><div>$ vi /etc/profile.d/dfs.sh
</div></code></pre>
<p><img src="image-26.png" alt="alt text"><br>
  然后输入：</p>
<pre class="hljs"><code><div>$ source /etc/profile
$ java -version
</div></code></pre>
<p><img src="image-27.png" alt="alt text"><br>
  说明jdk安装成功</p>
</li>
<li>
<p><strong>hadoop安装</strong></p>
<p>  将hadoop压缩包解压至指定目录下，打开etc/profile进行环境变量的修改：<br>
<img src="image-28.png" alt="alt text"><br></p>
</li>
<li>
<p><strong>zooKeeper安装</strong></p>
<p>  将zookeeper压缩包解压至指定目录下，打开etc/profile进行环境变量的修改：<br>
<img src="image-24.png" alt="alt text"><br>
  然后需要修改zoo.cgf，在之后会提到。<br></p>
</li>
<li>
<p><strong>hbase安装</strong></p>
<p>  将hbase压缩包解压至指定目录下，打开etc/profile进行环境变量的修改：<br>
<img src="image-25.png" alt="alt text"><br>
  修改hbase-env.sh<br>
<img src="image-29.png" alt="alt text"><br></p>
</li>
<li>
<p><strong>虚拟机复制</strong></p>
<p>  将样本机复制两次样本，一共有三台虚拟机，命名为hadoop081，hadoop082，hadoop083：<br>
<img src="image-8.png" alt="alt text"><br>
  将两台主机的网卡分别改为对应的IP，再修改其主机名。修改IP之前已经展示，接下来就展示主机名修改。命令输入：</p>
<pre class="hljs"><code><div>$ vim /etc/hostname
</div></code></pre>
<p><img src="image-9.png" alt="alt text"><br>
  如上图为hadoop082主机名的修改。</p>
</li>
</ul>
<ol>
<li>节点分配文件</li>
</ol>
<ul>
<li>
<p><strong>core-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;fs.defaultFS&lt;/name&gt;
            &lt;value&gt;hdfs://hadoop081:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
            &lt;value&gt;/var/big_data&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>hdfs-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
      &lt;property&gt;
              &lt;name&gt;dfs.replication&lt;/name&gt;
              &lt;value&gt;2&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
              &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
              &lt;value&gt;hdfs://hadoop083:9868&lt;/value&gt;
      &lt;/property&gt;
  &lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>yarn-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
            &lt;value&gt;hadoop081&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
            &lt;value&gt;256&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
            &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
            &lt;value&gt;1540&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
            &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
            &lt;value&gt;1540&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
             &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>mapred-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
      &lt;property&gt;
              &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
              &lt;value&gt;yarn&lt;/value&gt;
      &lt;/property&gt;
&lt;/configuration&gt;
'''
</div></code></pre>
</li>
<li>
<p><strong>hbase-site.xml</strong></p>
<pre class="hljs"><code><div>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/module/hbase-2.5.4/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.rootdir&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop081:9000/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;hadoop081,hadoop082,hadoop083&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
        &lt;value&gt;/opt/module/zookeeper-3.8.2/zkData&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.master.info.port&lt;/name&gt;
        &lt;value&gt;16010&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</div></code></pre>
</li>
<li>
<p><strong>zoo.cfg</strong></p>
<pre class="hljs"><code><div># The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/opt/module/zookeeper-3.8.2/zkData
# the port at which the clients will connect
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to &quot;0&quot; to disable auto purge feature
#autopurge.purgeInterval=1

## Metrics Providers
#
# https://prometheus.io Metrics Exporter
#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider
#metricsProvider.httpHost=0.0.0.0
#metricsProvider.httpPort=7000
#metricsProvider.exportJvmInfo=true
server.1=hadoop081:2888:3888
server.2=hadoop082:2888:3888
server.3=hadoop083:2888:3888
</div></code></pre>
</li>
</ul>
<ol start="5">
<li>
<p>单机完全分布集群启动
<br>
  在三台机子上先启动各自的zookeeper，随后查看各自节点的zookeeper是否成功启动。</p>
<pre class="hljs"><code><div>$ zkServer.sh start
$ zkServer.sh status
</div></code></pre>
<p>  当出现以下的语句时表示zk启动完成：<br>
<img src="image-16.png" alt="alt text"><br>
  然后启动hdfs和yarn以及hbase：<br></p>
<pre class="hljs"><code><div>$ start-all.sh
$ start-hbase.sh
</div></code></pre>
<p>  查看各个节点是否启动成功：<br></p>
<ul>
<li>hadoop081:<br>
<img src="image-18.png" alt="alt text"></li>
<li>hadoop082:<br>
<img src="image-17.png" alt="alt text"></li>
<li>hadoop083:<br>
<img src="image-19.png" alt="alt text">
<br>
  经验证，与配置文件的内容要求一致，节点启动成功，随后检查web是否能够成功访问。</li>
<li>hdfs:<br>
<img src="image-21.png" alt="alt text"></li>
<li>yarn:<br>
<img src="image-22.png" alt="alt text"></li>
<li>hbase:<br>
<img src="image-23.png" alt="alt text">
<br>
  均显示正常，表明单机完全分布启动成功。<br></li>
</ul>
</li>
<li>
<p>三机完全分布集群网络配置</p>
<p>为了实现三机之间的通信以及文件的传输，按照以下的步骤配置集群网络：<br>
（1）.将三个主机该为桥接模式，勾选复制物理网络连接状态选项，并连接在同一个局域网下，本次实验的局域网选择的是手机WiFi热点连接，网段前三位为192.168.3。<br>
（2）.修改三个虚拟机的ip地址，使得其与主机的网段的前三位相同，第四位设置为该虚拟机编号的地址，如192.168.3.82。<br>
（3）.修改三个虚拟机的GATEWAY值，使得三个主机的网关相同，均为192.168.3.111.<br>
修改完成后其中一台机器的主机ip以及虚拟机ip地址配置如下：<br>
<img src="ni3.png" alt="alt text"><br>
<img src="ni2.png" alt="alt text"><br>
尝试ping通其他机器，成功，证明网络配置已完成<br>
<img src="ni1.png" alt="alt text"><br></p>
</li>
<li>
<p>三机完全分布集群启动</p>
<p>  具体启动过程和单机完全分布一致，主要展示启动后的web访问图片:<br>
<img src="6a3c3ab456b516b655776b990a6127a.jpg" alt="alt text">
从左到右分别展示hbase，hdfs和yarn的界面，均可访问。表示三机完全分布式启动成功。</p>
</li>
</ol>
<h3 id="26-%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0">2.6 算法及实现</h3>
<blockquote>
<p>  MapReduce是由hadoop提供的一个开源软件框架，基于该框架能够容易地编写应用程序运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。</p>
</blockquote>
<p>  在本次实验中，我们使用MapReduce框架实现了词频统计及倒排索引的Java程序，能够在hadoop上分布式运行，并将处理结果导入进hbase当中。<br>
  Java项目使用jdk1.8.0_422。采用Maven自动导入hadoop上MapReduce框架的相关依赖。</p>
<h4 id="261-pomxml%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">2.6.1 pom.xml配置文件</h4>
<pre class="hljs"><code><div>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.test&lt;/groupId&gt;
    &lt;artifactId&gt;InvertedMapReduce&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
            &lt;version&gt;3.3.5&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
            &lt;version&gt;3.3.5&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
            &lt;artifactId&gt;hbase-common&lt;/artifactId&gt;
            &lt;version&gt;2.5.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;
            &lt;version&gt;2.5.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;
            &lt;artifactId&gt;hbase-mapreduce&lt;/artifactId&gt;
            &lt;version&gt;2.5.10&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</div></code></pre>
<h4 id="262-map%E9%98%B6%E6%AE%B5%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81%E5%8F%8A%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E">2.6.2 Map阶段实现代码及算法说明</h4>
<ul>
<li>
<p><strong>InvertedMapper.java代码</strong></p>
<pre><code>  ```
  public class InvertedMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;
  {
      private final Text keyInfo = new Text();    // 表示单词的键
      private final Text valueInfo = new Text(&quot;1&quot;);  // 表示句子编号和某单词出现次数的// 单词和其在句子中出现的次数

      @Override
      protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException
      {
          // 将输入的文本行拆分为单词和句子编号
          String[] orderedSentences = value.toString().split(&quot; &quot;);

          // 获取文件名
          FileSplit filesplit = (FileSplit) context.getInputSplit();
          String filename = filesplit.getPath().getName();

          String[] sentences = Arrays.copyOfRange(orderedSentences, 1, orderedSentences.length); // 获取句子中的单词数组

          // 遍历句子中的单词，构建mapper，输出的形式应该是&lt;单词:文件名,1&gt;
          for (String word : sentences)
          {
              keyInfo.set(word+&quot;:&quot;+filename);
              context.write(keyInfo,valueInfo);
          }
      }
  }
  ```
</code></pre>
</li>
<li>
<p><strong>类定义</strong></p>
<p>  InvertedMapper类继承自 <code>Mapper&lt;LongWritable, Text, Text, Text&gt;</code>，其中 <code>Mapper</code> 是Hadoop中的核心类，用于将输入数据映射为键值对。它实现了 <code>map()</code> 方法，处理输入数据并生成中间结果，供后续的Reducer处理。</p>
</li>
<li>
<p><strong>数据结构与定义</strong></p>
<ol>
<li><strong>输入数据格式</strong>：</li>
</ol>
<ul>
<li><code>LongWritable key</code>：文件中当前处理行的偏移量，作为行号。</li>
<li><code>Text value</code>：代表文件中的一行数据，假设每行数据包含一个句子编号及其对应的句子文本。</li>
</ul>
<ol start="2">
<li><strong>输出键值对</strong>：</li>
</ol>
<ul>
<li><strong>键 (<code>Text</code>)</strong>：格式为 <code>word:filename</code>，表示某个单词出现在某个文件中。</li>
<li><strong>值 (<code>Text</code>)</strong>：固定为 <code>&quot;1&quot;</code>，表示每次遇到该单词在该文件中出现一次。</li>
</ul>
</li>
<li>
<p><strong>算法核心</strong></p>
<p><strong><code>map()</code> 方法</strong>：</p>
<ul>
<li>
<p><strong>输入</strong>：</p>
<ul>
<li><code>key</code>：行号（LongWritable类型），在这段代码中没有使用。</li>
<li><code>value</code>：表示一行输入文本（Text类型）。</li>
<li><code>context</code>：提供了与Hadoop框架通信的上下文，允许Mapper将结果输出。</li>
</ul>
</li>
<li>
<p><strong>处理过程</strong>：</p>
<ul>
<li>
<p><strong>拆分行文本</strong>：使用 <code>value.toString().split(&quot; &quot;)</code> 将输入的文本行按空格拆分为一个单词数组。拆分后的第一个元素（句子编号）被忽略，后续的元素是句子中的单词。</p>
</li>
<li>
<p><strong>获取文件名</strong>：通过 <code>FileSplit</code> 获取当前处理的输入文件名，这个文件名会与每个单词组合在一起，用作键的一部分。</p>
</li>
<li>
<p><strong>构建键值对</strong>：通过遍历句子中的每个单词，将单词与文件名组合（格式为 <code>word:filename</code>），然后将该组合作为键，&quot;1&quot; 作为值（代表该单词在该文件中出现过一次），并输出到 <code>context</code> 中。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="263-combine%E9%98%B6%E6%AE%B5%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81%E5%8F%8A%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E">2.6.3 Combine阶段实现代码及算法说明</h4>
<ul>
<li>
<p><strong>InvertedCombiner.java代码</strong></p>
<pre class="hljs"><code><div>public class InvertedCombiner extends Reducer&lt;Text,Text,Text,Text&gt; {
    private final Text valueInfo = new Text();

    @Override
    protected void reduce(Text key,Iterable&lt;Text&gt; values,Context context) throws IOException,InterruptedException {
        int sum = 0;
        for (Text value:values){
            sum += Integer.parseInt(value.toString());
        }
        int fileNameIndex = key.toString().indexOf(&quot;:&quot;);
        //重设value和key值
        valueInfo.set(key.toString().substring(fileNameIndex+1)+&quot;:&quot;+sum);
        key.set(key.toString().substring(0,fileNameIndex));
        //输出应该是&lt;单词,文件名:次数&gt;
        context.write(key,valueInfo);
    }
}
</div></code></pre>
</li>
<li>
<p><strong>类定义</strong></p>
<p>  <code>InvertedCombiner</code>类继承自 <code>Reducer&lt;Text, Text, Text, Text&gt;</code>：它实现了 <code>reduce()</code> 方法，将Mapper生成的中间结果进行局部聚合。输入键值对为 <code>&lt;Text, Text&gt;</code>，输出的键值对也是 <code>&lt;Text, Text&gt;</code>。</p>
</li>
<li>
<p><strong>Combiner在MapReduce中的作用</strong></p>
<ul>
<li>
<p><strong>Mapper阶段的输出</strong>：在Mapper阶段，每行文本被处理后，生成的键值对是 <code>&lt;word:filename, 1&gt;</code>，表示某个单词在某个文件中出现了一次。对于同一个文件中的同一个单词，可能会产生多个键值对，如：</p>
<pre class="hljs"><code><div>&lt;word1:file1, 1&gt;
&lt;word1:file1, 1&gt;
&lt;word2:file1, 1&gt;
</div></code></pre>
</li>
<li>
<p><strong>Combiner阶段的优化</strong>：Combiner相当于一个局部的Reducer，它的作用是对Mapper输出的结果进行局部合并，减少数据传输量。在 <code>InvertedCombiner</code> 中，它负责计算出同一文件中某个单词的总出现次数，并将结果重新格式化为 <code>&lt;单词, 文件名:次数&gt;</code> 的形式。例如：</p>
<pre class="hljs"><code><div>Mapper 输出: &lt;word1:file1, 1&gt;, &lt;word1:file1, 1&gt;
Combiner 输出: &lt;word1, file1:2&gt;
</div></code></pre>
</li>
</ul>
<p>  这样，在Reducer阶段传输的数据量大大减少，从而一定程度提高了性能。</p>
</li>
<li>
<p><strong>算法实现</strong></p>
<p><code>reduce()</code> 方法：</p>
<ul>
<li>
<p><strong>输入</strong>：</p>
<ul>
<li><code>key</code>：一个文本类型的键，表示Mapper输出的键，格式为 <code>word:filename</code>。</li>
<li><code>values</code>：一个 <code>Iterable&lt;Text&gt;</code> 集合，表示Mapper输出的所有值。每个值是 &quot;1&quot;，表示单词在该文件中出现一次。</li>
</ul>
</li>
<li>
<p><strong>处理过程</strong>：</p>
<ul>
<li>
<p><strong>计算单词出现的总次数</strong>：遍历 <code>values</code> 集合，累加每个值（这里每个值都是 &quot;1&quot;），得到单词在某个文件中的总出现次数。</p>
</li>
<li>
<p><strong>拆分键，调整输出格式</strong>：通过 <code>key.toString().indexOf(&quot;:&quot;)</code> 找到<code>word:filename</code> 字符串中 <code>:</code> 的位置，方便后续进行拆分。使用 <code>substring</code> 方法将 <code>key</code> 拆分为 <code>word</code> 和 <code>filename</code>。</p>
</li>
<li>
<p><strong>重设键值对</strong>：将 <code>key</code> 设置为单词（仅保留单词部分，不再包含文件名）。将 <code>valueInfo</code> 设置为文件名和单词出现的总次数，格式为 <code>filename:count</code>。</p>
</li>
</ul>
</li>
<li>
<p><strong>输出</strong>：</p>
<p>  输出的键为单词，值为 <code>filename:count</code>，即 <code>&lt;单词, 文件名:次数&gt;</code> 的形式。</p>
</li>
</ul>
</li>
</ul>
<h4 id="264-reduce%E9%98%B6%E6%AE%B5%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81%E5%8F%8A%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E">2.6.4 Reduce阶段实现代码及算法说明</h4>
<ul>
<li>
<p><strong>InvertedIndexReducer.java代码</strong></p>
<pre class="hljs"><code><div>public class InvertedReducer extends TableReducer&lt;Text,Text, ImmutableBytesWritable&gt; {
    private static final Text result = new Text();
    @Override
    protected void reduce(Text key,Iterable&lt;Text&gt; values,Context context) throws IOException, InterruptedException {
        StringBuilder fileList = new StringBuilder();
        for (Text value:values){
            fileList.append(value.toString()).append(&quot;;&quot;);
        }
        result.set(fileList.toString());
        Put put = new Put(key.toString().getBytes());
        put.addColumn(&quot;info&quot;.getBytes(), &quot;index&quot;.getBytes(), result.toString().getBytes());
        context.write(null, put);
    }
}
</div></code></pre>
</li>
<li>
<p><strong>类定义</strong></p>
<p>  <code>InvertedReducer</code>类继承自 <code>TableReducer&lt;Text, Text, ImmutableBytesWritable&gt;</code>。用于将输入的 key 和 values 进行处理，并将结果输出到 HBase 表中。</p>
</li>
<li>
<p><strong>算法实现</strong></p>
<p><code>reduce()</code> 方法：</p>
<ul>
<li>
<p><strong>输入</strong>：</p>
<ul>
<li><code>key</code>：一个文本类型的键，表示Combiner输出的键，格式为 <code>word</code>。</li>
<li><code>values</code>：一个 <code>Iterable&lt;Text&gt;</code> 集合，表示Combiner输出的所有值。每个值是 <code>filename:count</code>，表示单词在该文件中的总出现次数。</li>
</ul>
</li>
<li>
<p><strong>处理过程</strong>：</p>
<ul>
<li>
<p><strong>字符串拼接</strong>：
代码通过遍历 <code>Iterable&lt;Text&gt; values</code>，逐一获取每个 <code>Text</code> 值，并将它们拼接到 <code>fileList</code> 字符串中。每个值之间用 <code>;</code> 作为分隔符。</p>
</li>
<li>
<p><strong>构造 HBase Put 对象</strong>：
<code>Put</code> 是 HBase 的数据操作对象，用于将数据存储到 HBase 表中。代码通过将 <code>key</code> 转换为字节数组来创建一个 <code>Put</code> 对象。之后，通过 <code>put.addColumn()</code> 方法，向名为 <code>info</code> 的列族和 <code>index</code> 列中添加数据，值是拼接后的 <code>fileList</code> 字符串。</p>
</li>
<li>
<p><strong>写入结果到上下文</strong>：
<code>context.write(null, put)</code> 表示将构造好的 <code>Put</code> 对象写入到 HBase 表中。在这个例子中，<code>key</code> 是 null，这表示输出的行键已经在 <code>Put</code> 对象中定义。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="265-driver%E9%98%B6%E6%AE%B5%E4%B8%BB%E5%87%BD%E6%95%B0">2.6.5 Driver阶段主函数</h4>
<ul>
<li>
<p><strong>InvertedIndexDriver.java代码</strong></p>
<pre class="hljs"><code><div>public class Driver {
    public static void main(String[] args) throws ClassNotFoundException, IOException,InterruptedException {
        Configuration conf = new Configuration();
        //hdfs 主NameNode通信地址
        conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs://hadoop:9000&quot;);
        //yarn 主resourcemanager通信地址
        conf.set(&quot;yarn.resourcemanager.hostname&quot;,&quot;hadoop&quot;);
        //zookeeper集群，连接到HMaster
        conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;hadoop&quot;);

        Job job = Job.getInstance(conf);
        job.setJarByClass(Driver.class);
        job.setMapperClass(InvertedMapper.class);
        job.setCombinerClass(InvertedCombiner.class);
        job.setReducerClass(InvertedReducer.class);
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);

        job.getConfiguration().setStrings(&quot;mapreduce.reduce.shuffle.memory.limit.percent&quot;, &quot;0.15&quot;);

        FileInputFormat.setInputPaths(job,new Path(args[0]));

        TableMapReduceUtil.initTableReducerJob(&quot;InvertedIndexTable&quot;,InvertedReducer.class,job);
        boolean res = job.waitForCompletion(true);
        System.exit(res?0:1);
    }
}
</div></code></pre>
</li>
<li>
<p><strong>类定义</strong></p>
<p><code>Driver</code>作为Hadoop MapReduce的驱动程序，负责配置和启动作业。其核心任务是使用 <code>InvertedMapper</code>、<code>InvertedCombiner</code> 和 <code>InvertedReducer</code> 来处理 HDFS 中的数据，并将结果写入 HBase 表中。</p>
</li>
<li>
<p><strong>算法实现</strong></p>
<ol>
<li>
<p><strong>异常处理</strong></p>
<p><code>main</code>方法抛出了一些异常，常见于 Hadoop 程序，如 <code>ClassNotFoundException</code>、<code>IOException</code> 和 <code>InterruptedException</code>，用于处理分布式作业的异常情况。</p>
</li>
<li>
<p><strong>Configuration 配置对象</strong></p>
<p><code>Configuration conf = new Configuration();</code>：创建一个 Hadoop 配置对象 <code>conf</code>，用于存储作业的配置信息。Hadoop 集群的连接信息如下：</p>
<ul>
<li><code>conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs://hadoop:9000&quot;);</code>：设置 HDFS 的主 NameNode 的地址，即文件系统的默认根路径。</li>
<li><code>conf.set(&quot;yarn.resourcemanager.hostname&quot;,&quot;hadoop&quot;);</code>：配置 Yarn 的 ResourceManager 地址，负责作业的资源调度。</li>
<li><code>conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;hadoop&quot;);</code>：配置 Zookeeper 集群的地址，Zookeeper 用于管理 HBase 的 HMaster。</li>
</ul>
</li>
<li>
<p><strong>作业初始化</strong></p>
<ul>
<li><code>Job job = Job.getInstance(conf);</code>：创建一个新的 <code>Job</code> 实例，用于配置和管理 MapReduce 作业。</li>
<li><code>job.setJarByClass(Driver.class);</code>：设置包含主类的 JAR 文件，这个 JAR 包含作业的执行代码，并且可以在分布式节点上运行。</li>
</ul>
</li>
<li>
<p><strong>设置 Mapper、Combiner 和 Reducer 类</strong></p>
<ul>
<li><code>job.setMapperClass(InvertedMapper.class);</code>：指定作业的 Mapper 类，负责将输入数据拆分并生成键值对。</li>
<li><code>job.setCombinerClass(InvertedCombiner.class);</code>：指定作业的 Combiner 类，用于在 Mapper 输出后，Reducer 之前对数据进行本地聚合。</li>
<li><code>job.setReducerClass(InvertedReducer.class);</code>：指定 Reducer 类，用于最终的聚合和结果输出。</li>
</ul>
</li>
<li>
<p><strong>设置 Map 输出的键值类型</strong></p>
<ul>
<li><code>job.setMapOutputKeyClass(Text.class);</code>：Mapper 输出的键的类型为 <code>Text</code>，即 Hadoop 的文本类型。</li>
<li><code>job.setMapOutputValueClass(Text.class);</code>：Mapper 输出的值的类型也是 <code>Text</code>，即文本数据。</li>
</ul>
</li>
<li>
<p><strong>其他配置</strong></p>
<ul>
<li><code>job.getConfiguration().setStrings(&quot;mapreduce.reduce.shuffle.memory.limit.percent&quot;, &quot;0.15&quot;);</code>：设置 Reduce 任务的内存限制，用于限制 MapReduce 过程中的内存使用。</li>
</ul>
</li>
<li>
<p><strong>输入路径配置</strong></p>
<ul>
<li><code>FileInputFormat.setInputPaths(job, new Path(args[0]));</code>：通过 <code>FileInputFormat</code> 设置作业的输入路径，该路径来自命令行参数 <code>args[0]</code>。</li>
</ul>
</li>
<li>
<p><strong>与 HBase 的集成</strong></p>
<pre class="hljs"><code><div>TableMapReduceUtil.initTableReducerJob(&quot;InvertedIndexTable&quot;, InvertedReducer.class, job);
</div></code></pre>
<p>  这行代码使用 <code>TableMapReduceUtil</code> 工具类将结果输出到 HBase 表中，指定表名为 <code>&quot;InvertedIndexTable&quot;</code>。第二个参数 <code>InvertedReducer.class</code> 是 Reducer 类，用于将结果写入 HBase。通过这种方式，作业的输出不是写入 HDFS 文件系统，而是直接插入到 HBase 表中。</p>
</li>
</ol>
</li>
</ul>
<h3 id="27-%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E4%B8%8E%E5%88%86%E6%9E%90">2.7 运行结果与分析</h3>
<ul>
<li><strong>运行结果</strong><br>
  首先使用java程序里面的UpLoad类将本地处理好的数据集上传到集群hdfs的“input/data/”目录下：<br>
<img src="19fb02e2fd5c32647e05fcf285a29f2.jpg" alt="alt text"><br>
  如图表示上传成功。<br>
  使用hbase shell命令新建一个名为“InvertedIndexTable”的表格：<pre class="hljs"><code><div>create 'InvertedIndexTable'
</div></code></pre>
  将jar包上传至虚拟机中。使用如下命令运行jar包：<pre class="hljs"><code><div>hadoop jar test.jar /input/data
</div></code></pre>
  如图所示即为运行成功：<br>
<img src="c8a37b934cff62bdc49c501b519c649.png" alt="alt text"><br>
  最后在hbase shell里面查看表格：<br>
<img src="image-14.png" alt="alt text">
  输出无误，表示运行完成。
  随后验证检索功能，输入命令：<br><pre class="hljs"><code><div>$ scan 'Final',{STARTROW =&gt; 'ac'}
</div></code></pre>
  部分结果显示：<br>
<img src="image-30.png" alt="alt text"><br>
  表明倒排索引结果成功写入hbase中。</li>
<li><strong>运行时间对比</strong>
  在完成伪分布式计算，单机分布式计算和三机分布式计算之后，我们对其运行时长进行对比，得以突出多机完全分布式的优越性。
<ul>
<li>三机完全分布:<br>
<img src="84fe733d03a55ec0902c45c00dc1b37-1.png" alt="alt text">
<br>
  通过yarn进程的开始结束时间计算进程的总时长为42分钟。
<br></li>
<li>单机完全分布:<br>
<img src="241d40f16d13b70385e11fc995614fc.png" alt="alt text">
<br>
  通过yarn进程的开始结束时间计算进程的总时长为92分钟。<br></li>
<li>伪分布:<br>
<img src="hadoop.png" alt="alt text">
<br>
  经过对比不难发现三机完全分布运行的时间最短，经过分析我们发现是虚拟机依赖的主机所提供的性能（cpu和内存）所带来的差别，相对于单机完全分布（三个节点一共3核6GB内存），三机完全分布能充分利用三台电脑的处理器和内存，从而有更高的性能，相应的进程的时长也就越短。实验结果充分体现了分布式计算的优势。</li>
</ul>
</li>
</ul>
<h3 id="28-%E6%80%BB%E7%BB%93">2.8 总结</h3>
<p>  通过为期一周的小学期学习和一个月以来断断续续的实验实践，我们从初次接触大数据时的一无所知渐渐熟悉了大数据的基本技术和Hadoop架构，慢慢了解了大数据技术的特点及其应用场景，同时掌握了Hadoop分布式架构的优势、工作原理以及MapReduce的运行机制。<br>
  在实验中，我们动手实践，从搭建环境入手，分别在虚拟机上构建了伪分布式和完全分布式的架构，并自主编写了MapReduce程序。这一过程几多困难曲折，不论是完全分布虚拟主机桥接模式的网络配置，还是编译MapReduce Java程序的Maven依赖导入问题，还是实际运行倒排索引时内存不足导致yarn下线，面对密密麻麻各种各样难以言状的报错和bug，我们不得不辗转于各大技术论坛，求助于万能的chatgpt，耗费无数的日夜交流，讨论，合作，不断祈祷实验能够顺利完成。尽管如此，当倒排索引的结果最终成功写入HBase之后，虽心力交瘁，但满身轻松愉快，收获颇丰。我们不仅对Hadoop分布式架构和HBase数据库有了更加深入的认识，也提高了自主发现问题解决问题的能力，极大增进了了小组成员间的默契和团队合作能力。<br>
  最后，感谢本学期中郭老师对课程内容的精心设计和在小学期期间的认真讲解，也祝愿郭老师在接下来的工作、生活中一切顺利。</p>

</body>
</html>
